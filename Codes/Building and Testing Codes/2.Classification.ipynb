{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb67ce-2dc7-4e98-876e-9552e8fbcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570d4c-cc40-4305-8e89-04cd08100aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Dog_Health_Preprocessed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dbc8e3-bf7a-4378-adad-c78cb285ac10",
   "metadata": {},
   "source": [
    "# MODEL 1 WITH OVERSAMPLING AND UNDERSAMPLING COMBINED --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f953198-5fb1-4610-b792-1738f3dd3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df[\"Healthy\"] == 1]\n",
    "df_minority = df[df[\"Healthy\"] == 0]\n",
    "\n",
    "# Strategy: downsample majority, upsample minority to match the same size (2500 <-> 2500)\n",
    "majority_downsampled = resample(df_majority,\n",
    "                                replace=False,\n",
    "                                n_samples=2500,\n",
    "                                random_state=42)\n",
    "\n",
    "minority_upsampled = resample(df_minority,\n",
    "                              replace=True,\n",
    "                              n_samples=2500,\n",
    "                              random_state=42)\n",
    "\n",
    "# Combine the two to get a balanced dataset\n",
    "df_balanced = pd.concat([majority_downsampled, minority_upsampled])\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verify the new class balance\n",
    "df_balanced[\"Healthy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910796db-0988-4df5-889b-3c922c9e8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df_balanced.drop(columns=[\"Healthy\"])\n",
    "y = df_balanced[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Train and report for each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Healthy\", \"Healthy\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f390a-6dcc-4f6b-a372-e8c47053c170",
   "metadata": {},
   "source": [
    "#### BEST MODEL IS RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44e290-3f49-40bd-92bd-cf5c93339448",
   "metadata": {},
   "source": [
    "# MODEL 2: WITH OVERSAMPLING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc656800-bc79-4064-9577-d2f66a4db6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split majority and minority\n",
    "df_majority = df[df[\"Healthy\"] == 1]\n",
    "df_minority = df[df[\"Healthy\"] == 0]\n",
    "\n",
    "# Oversample the minority class only\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "# Combine to create the new balanced dataset\n",
    "df_oversampled = pd.concat([df_majority, df_minority_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90844cca-3010-474c-b249-5ba8cfdc86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df_oversampled.drop(columns=[\"Healthy\"])\n",
    "y = df_oversampled[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Train and report for each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Healthy\", \"Healthy\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b8226-ed94-4749-8e93-0a936ec001f5",
   "metadata": {},
   "source": [
    "#### -- BEST MODEL RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4601e1-fcda-481a-9113-cd09c6a38025",
   "metadata": {},
   "source": [
    "# MODEL 3: WITH UNDERSAMPLING OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea75da-0a91-423c-a914-c312b76b8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 4: Undersampling (only)\n",
    "df_majority = df[df[\"Healthy\"] == 1]\n",
    "df_minority = df[df[\"Healthy\"] == 0]\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "df_undersampled = pd.concat([df_majority_downsampled, df_minority]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d93b8-db63-4c7c-96e8-74b52132f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df_undersampled.drop(columns=[\"Healthy\"])\n",
    "y = df_undersampled[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Train and report for each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Healthy\", \"Healthy\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814475f7-f318-4e8d-beb6-e33faf399a30",
   "metadata": {},
   "source": [
    "#### -- BEST MODEL GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abddcf7e-194b-41b1-a81d-78981901ab4e",
   "metadata": {},
   "source": [
    "# EVALAUATE THE BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd423e6-4849-484b-8a9c-876d1b5c1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper to train, evaluate and collect results\n",
    "def evaluate_model(X, y, model, label):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"Model\": label,\n",
    "        \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Train F1\": f1_score(y_train, y_train_pred),\n",
    "        \"Test F1\": f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "# Run for all 3 strategies\n",
    "results = []\n",
    "results.append(evaluate_model(\n",
    "    df_oversampled.drop(columns=[\"Healthy\"]),\n",
    "    df_oversampled[\"Healthy\"],\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    \"Oversampling (RF)\"\n",
    "))\n",
    "\n",
    "results.append(evaluate_model(\n",
    "    df_undersampled.drop(columns=[\"Healthy\"]),\n",
    "    df_undersampled[\"Healthy\"],\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    \"Undersampling (GB)\"\n",
    "))\n",
    "\n",
    "results.append(evaluate_model(\n",
    "    df_balanced.drop(columns=[\"Healthy\"]),\n",
    "    df_balanced[\"Healthy\"],\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    \"Mixed (RF)\"\n",
    "))\n",
    "\n",
    "# Display results as DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc429506-91a8-436c-93ae-c806960b1f3b",
   "metadata": {},
   "source": [
    "# MODEL 4: WITH SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303fdc4-f7ae-408d-b522-24947e864a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split into train/test\n",
    "X = df.drop(columns=[\"Healthy\"])\n",
    "y = df[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define models\n",
    "models = {\n",
    "    \"Random Forest (SMOTE)\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting (SMOTE)\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Step 6: Train and evaluate\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_sm)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Accuracy\": accuracy_score(y_train_sm, y_train_pred),\n",
    "        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Train F1\": f1_score(y_train_sm, y_train_pred),\n",
    "        \"Test F1\": f1_score(y_test, y_test_pred)\n",
    "    })\n",
    "\n",
    "# Step 7: Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Performance with SMOTE:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a080-368a-47d3-933d-042468053632",
   "metadata": {},
   "source": [
    "# --- MODEL FITTING --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a1f86-6525-466b-a083-df8e1b688a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X = df.drop(columns=[\"Healthy\"])\n",
    "y = df[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Predict and evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65992119-9ed5-4188-a22f-ea9bd6c26339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df_balanced.drop(columns=[\"Healthy\"])\n",
    "y = df_balanced[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Healthy\", \"Healthy\"]))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=[\"Not Healthy\", \"Healthy\"]).plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9fe6a-f11f-42b2-90ec-573651552ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, '../Models/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5733fb4-e73a-4f1b-a164-4c10d0a8e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model\n",
    "# loaded_model = joblib.load('model_filename.pkl')\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# # Save the model\n",
    "# with open('model.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "# # Load the model\n",
    "# with open('model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61955f-5cf1-4eee-8113-6082ca35e0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
