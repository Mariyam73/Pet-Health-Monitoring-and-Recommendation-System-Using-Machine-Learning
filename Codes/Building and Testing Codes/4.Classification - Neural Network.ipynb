{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNYxzSX0xBhp",
    "outputId": "f8a91243-262b-4131-a660-cb20232cac6f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTXuDhQ0xCVv",
    "outputId": "5cf1b883-93ff-4732-917b-a94fdeb5e4ef"
   },
   "outputs": [],
   "source": [
    "cd 'drive/MyDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGypNbwqxI3W"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c9CUBbYxObV"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('synthetic_dog_breed_health_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1jZ7tUUxRyF"
   },
   "outputs": [],
   "source": [
    "# Drop the ID column as it is not useful for prediction\n",
    "df_clean = df.drop(columns=[\"Synthetic\", \"Food Brand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqYt5qYSxUHs",
    "outputId": "83d8df81-fd2c-4180-a649-a693ce6a1ea1"
   },
   "outputs": [],
   "source": [
    "# Identify categorical and numerical features\n",
    "categorical_cols = df_clean.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "numerical_cols = df_clean.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "for col in numerical_cols:\n",
    "    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "for col in categorical_cols:\n",
    "    df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QxJUJBKYxXAc",
    "outputId": "427c048d-c20e-46d2-8908-e68ffe912910"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check label distribution\n",
    "label_distribution = df_clean['Healthy'].value_counts(normalize=True)\n",
    "\n",
    "# Plot label distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Healthy', data=df_clean)\n",
    "plt.title('Health Label Distribution')\n",
    "plt.xticks([0, 1], ['Not Healthy (0)', 'Healthy (1)'])\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Health Status')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats for numeric columns\n",
    "numeric_summary = df_clean[numerical_cols].describe()\n",
    "\n",
    "# Plot distributions for numeric columns\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df_clean[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Box plots for outlier detection\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df_clean[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "numeric_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxBxBayCxa9k",
    "outputId": "1d1cf2fe-30ed-4a40-d526-0abb8f6b5883"
   },
   "outputs": [],
   "source": [
    "# Remove Outliers\n",
    "\n",
    "# Use IQR method to detect and remove outliers in Weight (lbs)\n",
    "Q1 = df_clean[\"Weight (lbs)\"].quantile(0.25)\n",
    "Q3 = df_clean[\"Weight (lbs)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "df_no_outliers = df_clean[(df_clean[\"Weight (lbs)\"] >= lower_bound) & (df_clean[\"Weight (lbs)\"] <= upper_bound)]\n",
    "\n",
    "# Compare original vs filtered\n",
    "original_count = df_clean.shape[0]\n",
    "filtered_count = df_no_outliers.shape[0]\n",
    "\n",
    "original_count, filtered_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jY6rPjTjxeLM",
    "outputId": "56de89de-2437-400b-a55b-63ef30b95a37"
   },
   "outputs": [],
   "source": [
    "# Split and balance using SMOTE\n",
    "X = df_no_outliers.drop(columns=[\"Healthy\"])\n",
    "y = df_no_outliers[\"Healthy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Build the Neural Network\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_sm.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_sm, y_train_sm, epochs=30, batch_size=32,\n",
    "                    validation_split=0.2, verbose=0)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# 1. ðŸ“Š Classification Report\n",
    "print(\"ðŸ“„ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Healthy\", \"Healthy\"]))\n",
    "\n",
    "# 2. ðŸ”· Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Healthy\", \"Healthy\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Neural Network\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ðŸ“ˆ Train vs Validation Accuracy Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train vs Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A39otxoyzF0H",
    "outputId": "313d5af5-2ba6-4594-c399-7364dda18578"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Step 1: Compute class weights\n",
    "cw = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_sm), y=y_train_sm)\n",
    "class_weights = {i: w for i, w in enumerate(cw)}\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Step 2: Define the neural network\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_sm.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Add EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Step 4: Train with class weights and early stopping\n",
    "history = model.fit(\n",
    "    X_train_sm, y_train_sm,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(\"ðŸ“„ Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Healthy\", \"Healthy\"]))\n",
    "\n",
    "# Step 6: Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=[\"Not Healthy\", \"Healthy\"]).plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (NN with Class Weights + Early Stopping)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Plot accuracy curves\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train vs Validation Accuracy (with Early Stopping)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hajrt3atz-g9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
